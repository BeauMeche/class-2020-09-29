---
title: "Week 4, Day 1"
date: "9/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(readxl)
library(janitor)
```

Let's continue working with enrollment data. I have downloaded 5 years of fall enrollment data in to the `raw_data` directory from the [official source](https://registrar.fas.harvard.edu/faculty-staff/courses/enrollment/archived-course-enrollment-reports).

### Scene 1

**Prompt:** Write a pipe which creates an object named `d_2019` by reading in and cleaning up the data from Fall 2019. (You will need to examine the file names to determine which file this is.) You may consult and re-use the code from last week. The variable names in the tibble should be `id`,  `title`, `name`, `department` and `u_grad`. Keep only classes with more than 10 undergrads enrolled.

**Answer:** 

```{r sc1}
d_2019 <- 
  read_excel("raw_data/class_enrollment_summary_by_term_12.20.19.xlsx", 
             skip = 3) %>% 
  clean_names() %>% 
  filter(! is.na(course_title)) %>% 
  select( -instructor_full_name, -course_section_code, -(grad:total)) %>%
  rename_with(~ str_replace(.x, "course_", "")) %>% 
  group_by(id, title, name, department) %>% 
  summarize(u_grad = sum(u_grad), .groups = "drop") %>% 
  filter(u_grad > 10)
```

**Comment:** Encourage students to use this exercise as an excuse to practice having two RStudio sessions open. The best way to work with R/RStudio is to have multiple sessions open. One is for the problem set. A second is for the class work today. A third is for the class work from last week. That makes it easy to copy code from last week and use it today. It is a much worse workflow to have just one session, and then have to go find the Rmd file for last week which lives elsewhere. The only place you open a file from is the RStudio session open to that project's directory.

You might also point out that we don't need the group_by/summarize step. (We certainly did not use it last semester.) I think that it is only this year's data which really needs it, because of the large number of multiple section classes, like Gov 50. Or maybe we should have used this last year, but we didn't because it only affected a handful of classes, like Expos, which we failed to notice.

In fact, it is worth thinking harder about whether or not this combination is even what we want. Certainly, if we want to know enrollments, this is the right approach. There are 500 students in Expos. But what if we care about average class size, as experienced by Harvard students. Then aggregation by `id` may be the wrong approach. Data science is hard!


### Scene 2

**Prompt:** We could copy/paste this code 5 times, adjust the files names, and then read in each file. But, as you know from Chapter 4, that is a bad idea. It also scales very poorly. Create a function called `read_enrollent` which takes one argument, `file`. Use that function to read in the data from fall 2019 and assign it to an object called `d_2019_take_2`. Do you get the same answer as you did in Scene 1?

**Answer:** 

```{r sc2}
read_enrollment <- function (file){
  read_excel(file, 
             skip = 3) %>% 
  clean_names() %>% 
  filter(! is.na(course_title)) %>% 
  select( -instructor_full_name, -course_section_code, -(grad:total)) %>%
  rename_with(~ str_replace(.x, "course_", "")) %>% 
  group_by(id, title, name, department) %>% 
  summarize(u_grad = sum(u_grad), .groups = "drop") %>% 
  filter(u_grad > 10)
}

d_2019_take_2 <- read_enrollment(file = "raw_data/class_enrollment_summary_by_term_12.20.19.xlsx")

identical(d_2019, d_2019_take_2)
```

**Comment:** Our first function. Note how easy this is: Just take a working pipe and place it within a function wrapper. Pull out the relevant function arguments and, Voila! Very exciting. Having written a function, it is very good to test it. I think it is a concept too far to start talking about unit tests and the **testthat** package, but I would still mention it.

We would never leave the `identical()` check in the final Rmd without assigning the output somewhere. We can't have a random TRUE pop up in the html.

### Scene 3

**Prompt:** Call `read_enrollent()` five times, once for each of our data sets. Note how different the file names are. Real data is messy! Assign the result of each call to an object, `d_2019`, `d_2018` and so on. Should be easy . . .

Arrg! Depending in how you wrote `read_enrollment()`, you will probably be getting an error, for at least some of the years.  How annoying that Harvard changes the format! Make your function flexible enough to deal with all these files. Hint: You need to add at least one argument in addition to `file` so that you can change the behavior of the function when you call it. Give that new argument a sensible default.

**Answer:** 

```{r sc3}
read_enrollment <- function (file, skip_lines = 3){
  read_excel(file, 
             skip = skip_lines) %>% 
  clean_names() %>% 
  filter(! is.na(course_title)) %>% 
  select( -instructor_full_name, -course_section_code, -(grad:total)) %>%
  rename_with(~ str_replace(.x, "course_", "")) %>% 
  group_by(id, title, name, department) %>% 
  summarize(u_grad = sum(u_grad), .groups = "drop") %>% 
  filter(u_grad > 10)
}


d_2019 <- read_enrollment(file = "raw_data/class_enrollment_summary_by_term_12.20.19.xlsx")
d_2018 <- read_enrollment(file = "raw_data/class_enrollment_summary_by_term_10.24.18.xlsx", 
                          skip_lines = 2)
d_2017 <- read_enrollment(file = "raw_data/class_enrollment_summary_by_term_10.20.17.xlsx")
d_2016 <- read_enrollment(file = "raw_data/class_enrollment_summary_by_term_fall_2016.xlsx",
                          skip_lines = 0)
d_2015 <- read_enrollment(file = "raw_data/class_enrollment_summary_by_term_fall_2015.xlsx")

```

**Comment:** Too hard or too easy? I don't know. And it depends somewhat on the details of the original function, which might vary across students, even in the same breakout room. Still, this is a real problem using data from the wild. I think students should be able to tackle it . . .

I don't think that there are other important differences in the files besides the starting line, but I did not check that closely. We are lucky that the variable names (and order!) are constant for these five years.

### Scene 4

**Prompt:** Combine the five tibbles which you have into a single tibble which can then be used for analysis and graphics. There are many ways to do this, but we recommend `bind_rows()`. Hint: make use of the `.id` argument, which may be aided by placing the tibbles in a list.

```{r sc4}
x <- bind_rows(list(d_2015, d_2016, d_2017, d_2018, d_2019), .id = "year") %>% 
  mutate(year = as.numeric(year) + 2014)
```

**Comment:** Isn't there a better way to do this? Not one that I could find! Sometimes, I am embarrassed to show the students such hack-o-rama. But, I am also happy to model what professionals do and the above is what I would have done to solve this problem. Note also the necessary use of `list()`. The problem is much harder without `list()`. The students have all been exposed to `list()` in the tutorials and chapter 4, but it is nice to provide them with a real use case from the wild. It is also common to use `x` as the name of the main data set that one is working towards, and then using thereafter, in an exercise like this. 


### Scene 5

**Prompt:** Make an interesting plot with this data. Take that plot and publish it on Rpubs. Add a link to the Rpubs in the #general Slack channel.

**Comment**: I don't provide an answer here on purpose. It is time for the students to move beyond the Reproduce-the-Plot game. They need to start thinking for themselves. To do so, we need to give them space to practice. This is our first example. I am not sure if you will have time to get this far. Some groups probably will. If not, we can pick up with this on Thursday.

